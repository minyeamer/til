# ML Study
> 선형대수와 통계학으로 배우는 머신러닝 with 파이썬
  - [4. 랭크, 차원](#4-랭크-차원)
    - [4-4. 고유 벡터](#4-4-고유-벡터)
    - [4-5. 특이값 분해](#4-5-특이값-분해)
    - [4-6. 고윳값 분해](#4-6-고윳값-분해)
    - [4-7. 특이값 분해](#4-7-특이값-분해)
    - [4-8. 이차식 표현](#4-8-이차식-표현)
    - [4-9. 벡터의 미분](#4-9-벡터의-미분)
  - [5. 확률 변수와 확률 분포](#5-확률-변수와-확률-분포)
    - [5-1. 확률 변수](#5-1-확률-변수)
    - [5-2. 확률 분포](#5-2-확률-분포)
    - [5-3. 모집단과 표본](#5-3-모집단과-표본)
    - [5-4. 평균과 분산](#5-4-평균과-분산)
    - [5-5. 상관관계](#5-5-상관관계)
    - [5-6. 균일 분포](#5-6-균일-분포)
    - [5-7. 정규 분포](#5-7-정규-분포)
    - [5-8. 이항 분포](#5-8-이항-분포)
    - [5-9. 최대 가능도 추정](#5-9-최대-가능도-추정)
    - [5-10. 최대 사후 추정](#5-10-최대-사후-추정)
  - [6. 최적화](#6-최적화)
    - [6-1. 컨벡스 셋](#6-1-컨벡스-셋)
    - [6-2. 컨벡스 함수](#6-2-컨벡스-함수)

---

## 4. 랭크, 차원

### 4-4. 고유 벡터
- 고윳값, 고유 벡터 = 특성 값, 특성 벡터 = 행렬의 특성
- 고유 벡터(eigenvector): 벡터에 선형 변환을 취했을 때, 방향은 변하지 않고 크기만 변하는 벡터
- 고윳값(eigenvalue): 선형 변환 이후 변한 크기, 고유 벡터가 변환되는 크기의 정도

### 4-5. 특이값 분해
- 닮음(similar): $P^{-1}AP=B$를 만족하는 가역 행렬 $P$가 존재 시, 정사각 행렬 $A, B$는 서로 닮음
- 직교 닮음(orthogonally similar): $B=P^{-1}AP$를 만족하는 직교 행렬 $P$가 존재 시, $B$는 $A$에 직교 닮음
- 직교 대각화(orthogonal diagonalization): 직교 닮음의 경우에서 정사각 행렬 $B$가 대각 행렬 $D$일 경우
- 직교 대각화가 가능하기 위해 $A$는 반드시 대칭 행렬 ($A^T=A$) 이어야 함 (공분산 행렬 등)

### 4-6. 고윳값 분해
- 행렬을 고유 벡터, 고윳값의 곱으로 분해하는 것
- 직교 벡터 $P$를 고유 벡터를 이용해 만들고 대각 행렬의 원소에 해당하는 것이 고윳값
- $A=PDP^T$

### 4-7. 특이값 분해
- 정사각 행렬을 대상으로 하는 고윳값 분해와 달리 대상 행렬을 ${m}\times{n}$ 행렬로 일반화
- 인수 분해처럼 행렬의 차원 축소를 위한 도구로 사용
- 차원 축소를 $n$개의 점을 표현할 수 있는 기존 $p$보다 작은 차원인 $d$ 차원인 부분 공간(subspace)을 찾는 문제
- 데이터와 부분 공간으로부터의 수직 거리를 최소화(제곱합 $A^TA,AA^T$ 사용)하여 부분 공간을 찾음
- 특이값(singular value): 행렬 $A$를 제곱한 행렬의 고윳값에 루트를 씌운 값, $\sigma_1=\sqrt{\lambda_1}$
- $A=U\Sigma{V^T}$
- 행렬 U의 열벡터는 $AA^T$의 고유 벡터로 구성되는 left singular vector
- 행렬 V의 열벡터는 $A^TA$의 고유 벡터로 구성되는 right singular vector
- $\Sigma$의 대각 원소는 행렬 A의 특이값

### 4-8. 이차식 표현
- 다항식을 벡터 형태로 나타낼 때 사용하는 방법
- 대칭 행렬 $W$에 대해 $x^TWx$ 형태로 표현한 식
- 양정치(positive definite): $x^TWx>0, \text{ for all }x\neq{0}$ (행렬 W의 고윳값이 모두 0보다 큼)
- 음정치(negative definite): $x^TWx<0, \text{ for all }x\neq{0}$ (행렬 W의 고윳값이 모두 0보다 작음)

### 4-9. 벡터의 미분
- 타깃 $y=w^Tx=x^Tw$를 데이터 벡터 x에 대해 미분하면 w가 나옴

---

## 5. 확률 변수와 확률 분포

### 5-1. 확률 변수
- 확률(probability): 어떤 사건이 일어날 가능성을 수치화시킨 것
- 모든 확률은 0에서 1 사이에 있으며, 모든 경우인 표본 공간(sample space)의 $P(S)=1$
- 동시에 발생할 수 없는 사건들에 대해 각 사건의 합의 확률은 개별 확률이 일어날 확률의 합과 같음
- 확률 변수(random variable): 확률적으로 정해지는 변수, 동전 던지기에서 확률 변수 $X$는 0 또는 1의 값을 가짐
- 상수(constant): 변수와 다르게 항상 값이 고정된 수, $\pi=3.14$ 등
- 함수(function): 한 집합의 임의의 한 원소를 다른 집합의 한 원소에 대응시키는 관계

### 5-2. 확률 분포
- 확률 변수가 특정값을 가질 확률의 함수
- 이산 확률 변수: 확률 변수가 가질 수 있는 값을 셀 수 있음
- 확률 질량 함수: 이산 확률 변수에서 특정값에 대한 확률을 나타내는 함수, $p_X(x)=P(X=x)$
- 연속 확률 변수: 확률 변수가 가질 수 있는 값의 개수를 셀 수 없음
- 확률 밀도 함수: 연속 확률 변수의 분포를 나타내는 함수, $P(a\lt{X}\lt{b})=\int_a^bf_X(x)dx$
- 누적 분포 함수: 주어진 확률 변수가 특정값보다 작거나 같은 확률, $F_X(x)=P(X\in{-\infty,x}$
- 결합 확률 밀도 함수: 확률 변수 여러 개를 함께 고려하는 확률 분포, $P_{X,Y}(x,y)=P(X=x,Y=y)$
- 독립 항등 분포: 두 개 이상의 확률 변수를 고려할 때, 각 확률 변수가 통계적으로 독립이고 동일한 확률 분포(iid)를 따름

### 5-3. 모집단과 표본
- 모집단(population)은 관심이 있는 대상 전체, 표본(sample)은 모집단의 일부
- 모집단의 특성을 나타내는 대푯값을 모수(population parameter), 표본의 대푯값(sample statistic)을 표본 통계량

### 5-4. 평균과 분산
- 산술 평균: 모든 데이터값을 덧셈한 후 데이터 개수로 나누는 것
- 모평균: 모집단의 평균, $E(X)=\mu$
- 표본 평균: 모평균의 추정량, $\bar{X}=\frac{1}{n}\Sigma^n_{i=1}{x_i}$
- Location parameter: 평균의 변화로, 그래프의 위치 변화를 나타냄
- 분산: 데이터가 얼마나 퍼져 있는지를 수치화, 평균에 대한 편차 제곱의 평균
- 모분산: $Var(X)=E[(X-\mu)^2]=\sigma^2=E(X^2)-\mu^2$
- 표본 분산: $\sigma^2=s^2=\frac{1}{n-1}\Sigma^n_{i=1}(x_i-\bar{x})^2$
- $x_i-\bar{x}$는 평균에 대한 편차를 의미하며, 편차 제곱의 합을 n-1로 나누는 것은 자유도와 관련
- 자유도는 변수가 얼마나 자유로운지 나타내는 것으로,   
  분산을 구하는 시점에서 이미 표본 평균이 정해져 있어 자유롭게 정할 수 있는 데이터가 n-1개인 것을 의미
- Scale parameter: 분산과 같이 데이터의 흩어짐 정도를 결정하는 파라미터
- 표준 편차: 분산의 양의 제곱근으로 정의, 분산 계산 중 제곱으로 커진 결과를 다시 원래 단위로 조정하는 과정

$$E(\Sigma^n_{i=1}X_i)=n\mu_X\text{, }Var(\Sigma^n_{i=1}X_i)=n\sigma^2$$

### 5-5. 상관관계
- 공분산(covariance): 두 확률 변수의 상관관계를 나타내는 값, 같은 방향으로 움직이면 양수, 반대의 경우 음수
- 공분산은 변수 X의 편차와 변수 Y의 편차를 곱한 값의 평균, $Cov(X,Y)=E[(X-\mu_X)(Y-\mu_Y)]$
- 공분산 행렬: 확률 변수 간 분산, 공분산을 행렬로 표현한 것, 차원 축소 등에서 자주 사용
- 상관 계수: 공분산을 각 변수의 표준 편차로 나누어 계산

$$Corr(X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)}\sqrt{Var(Y)}}=\frac{Cov(X,Y)}{\sigma_X\sigma_Y}$$

### 5-6. 균일 분포
- 특정 범위 내에서 확률 분포가 균일한 분포
- 이산형 균일 분포라면 모든 확률 변수의 확률값이 동일, $X~U(1,N)$
- 연속형 균일 분포는 확률 변수의 범위가 연속형, $X~U(a,b)$

### 5-7. 정규 분포
- 정규 분포 또는 가우시안 분포는 평균을 중시믕로 대칭 형태를 띠는 종 모양 분포

$$f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2} \text{, } E(X)=\mu \text{, } Var(X)=\sigma^2$$

- $\frac{x-\mu}{\sigma}$는 머신러닝에서 쓰이는 데이터 표준화와 일치
- 표준 정규 분포: 평균이 0, 분산이 1인 정규 분포

### 5-8. 이항 분포
- 베르누이 분포, 베르누이 시행: 한 가지 실험에서 결과가 오직 2개인 시행
- 베르누이 시행의 성공 확률이 p일 때, 실패 확률은 1-p
- 이항 분포: 성공 확률이 p인 독립적인 베르누이 시행을 n회 했을 때, 성공 횟수 X가 따르는 이산형 확률 분포
- 다항 분포: 이항 분포를 일반화한 분포, 각 시행에서 나올 수 있는 결과가 m개로 확장

### 5-9. 최대 가능도 추정
- 가능도, 우도(likelihood): 파라미터가 주어질 때 해당 표본이 수집될 확률
- 가능도가 높다는 것은 해당 파라미터가 실젯값일 확률이 높다는 뜻
- 가능도 함수 $L(\theta|x)=\Pi^n_{i=1}{f(x_i|\theta)}$
- 로그 함수가 1대1 함수이기 때문에 가능도 함수에 로그 함수를 취할 수 있음 (log-likelihood function)
- 많은 확률을 곱할 경우 0에 가까워지기 때문에 계산상의 오류를 해결하기 위해 로그를 취함
- 최대 가능도 추정량(MLE): 파라미터별 가능도를 구해 가장 높은 가능도를 파라미터 추정값으로 사용

### 5-10. 최대 사후 추정
- 조건부 확률: 조건이 주어질 때의 확률, $P(A|B)=\frac{P({A}\bigcap{B})}{P(B)}$
- 두 사건이 독립일 경우, 두 사건이 동시에 발생할 확률($P({A}\bigcap{B}$)은 각 사건이 일어날 확률의 곱과 같음
- Bayesian: 확률 분포의 파라미터를 상수로 보는 일반적인 빈도주의(Frequentist)와 달리 파라미터를 확률 변수로 보는 방법
- 베이즈 추정: 파라미터 $\theta$가 확률 변수이므로 사전 확률 밀도 함수 $P(\theta)$를 구할 수 있음
- $P(\theta,x)=P(x|\theta)P(\theta)$
- 사후 확률 밀도 함수 $P(\theta|x)\propto{P(x|\theta)P(\theta)}$
- 최대 사후 추정(MAP): 사후 확률 밀도 함수 $P(\theta|x)$를 최대화하는 파라미터 $\theta$

---

## 6. 최적화

### 6-1. 컨벡스 셋
- 직선은 시작과 끝이 존재하지 않지만, 선분은 시작과 끝 지점이 존재
- 아핀 셋(affine set): $wx_1+(1-w)x_2\in{C}$를 만족하는 집합 C
- 함수 $f:\mathbb{R}^n\rightarrow\mathbb{R}^m$가 존재할 때,   
  선형 함수 $f(x)=Wx$,   
  아핀 함수 $f(x)=Wx+b$
- 컨벡스 셋(convex set): 두 점 $x_1,x_2\in{C}$에 대해 아래 조건을 만족하는 집합 C

$$wx_1+(1-w)x_2\in{C}\text{ }(0\le{w}\le{1})$$

- 컨벡스 셋은 두 점을 잇는 직선을 포함하는 아핀 셋과 달리 두 점 사이의 선분을 포함 (집합의 경계가 존재, 컨벡스 셋 $\subset$ 아핀 셋)
- 컨벡스 헐(convex hull): 선분이 아닌, 주어진 점들을 포함하는 컨벡스 셋
- 초평면(hyperplane): 서포트 벡터 머신 알고리즘의 핵심 개념, $\{x|w^Tx=b\}$
- 내적값 b가 0일 경우 벡터 w와 벡터 $x-x_0$는 수직
- 반공간(halfspace): 초평면으로 나뉜 공간의 일부, $\{w^Tx\le{b}\}$

### 6-2. 컨벡스 함수

- 컨벡스 함수: $$f(wx_1+(1-w)x_2 \le wf(x_1)+(1-w)f(x_2)$$
- 컨벡스 함수에서 등호가 없고 $0 \le w \le 1$이면 strictly 컨벡스라고 말함
- 콘케이브(concave): 컨벡스의 반대되는 개념 (-f가 컨벡스할 경우의 f)
- 컨벡스 함수의 예로 지수 함수, 절댓값 함수, 멱함수, 지시 함수, 최대 함수 등이 있음
- 미분이 가능하다는 말은 그래디언트(gradient) $\nabla f$가 존재한다는 뜻
- 1차 미분 조건: 최적값 탐색에 사용, $f(x_2) \ge f(x_1)+\nabla{f(x_1)^T}(x_2-x_1)$
- 그래디언트 값이 0일 때, $x_1$은 함수 f에 대한 전역 최솟값(global minimizer)
- 2차 미분 조건: 함수 f가 두 번 미분 가능할 경우, $\nabla^2f(x) \ge 0$
- 얀센의 부등식: $f(wx_1+(1-w)x_2) \le wf(x_1)+(1-w)f(x_2)$
